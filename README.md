# Website A/B Test Analysis

## Overview
This repository contains a comprehensive data analysis project that compares two website versions - the old one and the new one. The primary objective is to help the company make informed decisions by employing probability theory, A/B test techniques, and regression analysis.

## Approach

### Probability Theory
We utilize probability theory to assess the statistical significance of observed differences in key metrics between the two website versions. Calculating p-values and confidence intervals enables reliable evaluation.

### A/B Test Techniques
The A/B test is crucial for comparing the old and new versions under controlled conditions. Hypothesis testing ensures rigorous evaluation, and randomization guarantees test validity.

### Regression Approach
Using logistic regression and VIF assessment, we explore relationships between dependent variables like click-through rates and conversion rates. Identifying significant design elements aids website optimization decisions.

## Conclusion
After analyzing the data, we conclude that the new website version did not show a statistically significant improvement compared to the old one. As such, we recommend continuing with the old website for its proven performance.

For continuous improvement, periodic reassessment is crucial to adapt to changing user preferences. This project emphasizes evidence-based decision-making to achieve better website performance.

Feel free to explore the code, data, and documentation in this repository to understand the analysis process and apply it to your own projects.

## Contributing
We welcome contributions to enhance our analysis and make it more robust. Please feel free to submit pull requests.



